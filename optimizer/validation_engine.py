# –§–∞–π–ª: optimizer/validation_engine.py

import numpy as np
import pandas as pd
from typing import Dict, List, Tuple, Optional
import logging
from scipy import stats
try:
    from sklearn.metrics import silhouette_score
    from sklearn.cluster import KMeans
    SKLEARN_AVAILABLE = True
except ImportError:
    try:
        # –ü–æ–ø—ã—Ç–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –Ω–∞–∑–≤–∞–Ω–∏–µ–º –ø–∞–∫–µ—Ç–∞
        import sklearn.metrics
        import sklearn.cluster
        from sklearn.metrics import silhouette_score
        from sklearn.cluster import KMeans
        SKLEARN_AVAILABLE = True
    except ImportError:
        SKLEARN_AVAILABLE = False


class ValidationEngine:
    """
    –î–≤–∏–∂–æ–∫ –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –∏ –¥–µ—Ç–µ–∫—Ü–∏–∏ overfitting.
    
    –í–∫–ª—é—á–∞–µ—Ç:
    1. –î–µ—Ç–µ–∫—Ü–∏—è –ø–µ—Ä–µ–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø–æ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–º –∫—Ä–∏—Ç–µ—Ä–∏—è–º
    2. –ê–Ω–∞–ª–∏–∑ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –º–µ–∂–¥—É –æ–∫–Ω–∞–º–∏
    3. Out-of-sample —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
    4. –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∞—è –∑–Ω–∞—á–∏–º–æ—Å—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    """
    
    def __init__(self, config: Dict):
        self.config = config
        self.logger = logging.getLogger(__name__)
        self.overfitting_config = config['overfitting_detection']
        self.validation_config = config['validation']
    
    def detect_overfitting(self, train_score: float, val_score: float, test_score: float) -> bool:
        """
        –î–µ—Ç–µ–∫—Ç–∏—Ä—É–µ—Ç overfitting –ø–æ –¥–µ–≥—Ä–∞–¥–∞—Ü–∏–∏ performance –Ω–∞ out-of-sample –¥–∞–Ω–Ω—ã—Ö.
        
        Args:
            train_score: –û—Ü–µ–Ω–∫–∞ –Ω–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            val_score: –û—Ü–µ–Ω–∫–∞ –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö  
            test_score: –û—Ü–µ–Ω–∫–∞ –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            
        Returns:
            bool: True –µ—Å–ª–∏ –æ–±–Ω–∞—Ä—É–∂–µ–Ω overfitting
        """
        if not all(np.isfinite([train_score, val_score, test_score])):
            return True  # –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ scores = –ø–æ–¥–æ–∑—Ä–µ–Ω–∏–µ –Ω–∞ overfitting
        
        # 1. –î–µ–≥—Ä–∞–¥–∞—Ü–∏—è –æ—Ç –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –∫ —Ç–µ—Å—Ç—É
        if val_score > 0:
            val_to_test_degradation = (val_score - test_score) / val_score
            if val_to_test_degradation > self.overfitting_config['max_score_degradation']:
                self.logger.debug(f"–î–µ—Ç–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∞ –¥–µ–≥—Ä–∞–¥–∞—Ü–∏—è val‚Üítest: {val_to_test_degradation:.2%}")
                return True
        
        # 2. –î–µ–≥—Ä–∞–¥–∞—Ü–∏—è –æ—Ç —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏ –∫ —Ç–µ—Å—Ç—É
        if train_score > 0:
            train_to_test_degradation = (train_score - test_score) / train_score
            if train_to_test_degradation > self.overfitting_config['max_score_degradation']:
                self.logger.debug(f"–î–µ—Ç–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∞ –¥–µ–≥—Ä–∞–¥–∞—Ü–∏—è train‚Üítest: {train_to_test_degradation:.2%}")
                return True
        
        # 3. –¢–µ—Å—Ç –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ —Ö—É–∂–µ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏ (–∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π –ø—Ä–∏–∑–Ω–∞–∫ overfitting)
        if train_score > 0 and test_score < train_score * 0.6:
            self.logger.debug(f"–¢–µ—Å—Ç –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ —Ö—É–∂–µ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏: {test_score:.3f} vs {train_score:.3f}")
            return True
        
        return False
    
    def analyze_walk_forward_results(self, window_results: List[Dict]) -> Dict:
        """
        –ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ walk-forward –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ overfitting.
        
        Args:
            window_results: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤—Å–µ—Ö –æ–∫–æ–Ω walk-forward
            
        Returns:
            Dict: –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è–º–∏
        """
        successful_windows = [w for w in window_results if w.get('success', False)]
        
        if len(successful_windows) < 2:
            return {
                'status': 'insufficient_data',
                'warnings': ['–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —É—Å–ø–µ—à–Ω—ã—Ö –æ–∫–æ–Ω –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ overfitting'],
                'analysis': {}
            }
        
        analysis = {}
        warnings = []
        
        # 1. –ê–Ω–∞–ª–∏–∑ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        score_analysis = self._analyze_score_stability(successful_windows)
        analysis['score_stability'] = score_analysis
        warnings.extend(score_analysis.get('warnings', []))
        
        # 2. –ê–Ω–∞–ª–∏–∑ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        param_analysis = self._analyze_parameter_stability(successful_windows)
        analysis['parameter_stability'] = param_analysis
        warnings.extend(param_analysis.get('warnings', []))
        
        # 3. –ê–Ω–∞–ª–∏–∑ —á–∞—Å—Ç–æ—Ç—ã –ø—Ä–∏–±—ã–ª—å–Ω—ã—Ö –æ–∫–æ–Ω
        profitability_analysis = self._analyze_profitability_pattern(successful_windows)
        analysis['profitability'] = profitability_analysis
        warnings.extend(profitability_analysis.get('warnings', []))
        
        # 4. –ê–Ω–∞–ª–∏–∑ –¥–µ–≥—Ä–∞–¥–∞—Ü–∏–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        degradation_analysis = self._analyze_performance_degradation(successful_windows)
        analysis['degradation'] = degradation_analysis
        warnings.extend(degradation_analysis.get('warnings', []))
        
        # 5. –û–±—â–∏–π overfitting score
        overfitting_score = self._calculate_overfitting_score(analysis)
        analysis['overfitting_score'] = overfitting_score
        
        # 6. –§–∏–Ω–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
        if overfitting_score > 70:
            status = 'high_overfitting_risk'
            warnings.append('üî¥ –í–´–°–û–ö–ò–ô –†–ò–°–ö –ü–ï–†–ï–û–ü–¢–ò–ú–ò–ó–ê–¶–ò–ò')
        elif overfitting_score > 40:
            status = 'moderate_overfitting_risk'
            warnings.append('üü° –£–º–µ—Ä–µ–Ω–Ω—ã–π —Ä–∏—Å–∫ –ø–µ—Ä–µ–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏')
        else:
            status = 'low_overfitting_risk'
        
        return {
            'status': status,
            'overfitting_score': overfitting_score,
            'warnings': warnings,
            'analysis': analysis,
            'successful_windows': len(successful_windows),
            'total_windows': len(window_results)
        }
    
    def _analyze_score_stability(self, windows: List[Dict]) -> Dict:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å –æ—Ü–µ–Ω–æ–∫ –º–µ–∂–¥—É –æ–∫–Ω–∞–º–∏."""
        test_scores = [w.get('test_score', 0) for w in windows]
        val_scores = [w.get('val_score', 0) for w in windows]
        
        if not test_scores or all(s == 0 for s in test_scores):
            return {'status': 'no_data', 'warnings': ['–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ test scores']}
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ test scores
        test_mean = np.mean(test_scores)
        test_std = np.std(test_scores)
        test_cv = test_std / abs(test_mean) if test_mean != 0 else float('inf')
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ val scores
        val_mean = np.mean(val_scores) if val_scores else 0
        val_std = np.std(val_scores) if val_scores else 0
        
        warnings = []
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å
        if test_cv > 1.0:  # –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –≤–∞—Ä–∏–∞—Ü–∏–∏ > 100%
            warnings.append('‚ö†Ô∏è –ö—Ä–∞–π–Ω–µ –Ω–µ—Å—Ç–∞–±–∏–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –º–µ–∂–¥—É –æ–∫–Ω–∞–º–∏')
        elif test_cv > 0.5:
            warnings.append('‚ö†Ô∏è –ù–µ—Å—Ç–∞–±–∏–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –º–µ–∂–¥—É –æ–∫–Ω–∞–º–∏')
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç—Ä–µ–Ω–¥ –¥–µ–≥—Ä–∞–¥–∞—Ü–∏–∏
        correlation_with_time = None
        if len(test_scores) >= 3:
            try:
                # –ü—Ä–æ—Å—Ç–æ–π –∏ –Ω–∞–¥–µ–∂–Ω—ã–π —Å–ø–æ—Å–æ–± –ø–æ–ª—É—á–∏—Ç—å –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—é
                x_values = list(range(len(test_scores)))
                y_values = list(test_scores)
                correlation_result = stats.pearsonr(x_values, y_values)
                
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ
                if isinstance(correlation_result, tuple):
                    corr_value = correlation_result[0]
                else:
                    corr_value = getattr(correlation_result, 'correlation', correlation_result[0])
                
                correlation_with_time = float(corr_value) if not np.isnan(float(corr_value)) else 0.0  # type: ignore
                
                if correlation_with_time < -0.5:
                    warnings.append('üìâ –û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –¥–µ–≥—Ä–∞–¥–∞—Ü–∏—è performance —Å–æ –≤—Ä–µ–º–µ–Ω–µ–º')
            except Exception as e:
                self.logger.debug(f"–û—à–∏–±–∫–∞ –≤ —Ä–∞—Å—á–µ—Ç–µ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏: {e}")
                correlation_with_time = 0.0
        
        return {
            'test_score_mean': test_mean,
            'test_score_std': test_std,
            'test_score_cv': test_cv,
            'val_score_mean': val_mean,
            'score_trend': correlation_with_time if len(test_scores) >= 3 else None,
            'warnings': warnings
        }
    
    def _analyze_parameter_stability(self, windows: List[Dict]) -> Dict:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤."""
        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        all_params = []
        param_names = set()
        
        for window in windows:
            params = window.get('best_params', {})
            if params:
                all_params.append(params)
                param_names.update(params.keys())
        
        if len(all_params) < 2:
            return {'status': 'insufficient_data'}
        
        param_names = list(param_names)
        stability_scores = {}
        warnings = []
        
        for param_name in param_names:
            values = []
            for params in all_params:
                if param_name in params:
                    values.append(params[param_name])
            
            if len(values) < 2:
                continue
            
            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –≤–∞—Ä–∏–∞—Ü–∏–∏ –¥–ª—è —á–∏—Å–ª–æ–≤—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
            if all(isinstance(v, (int, float)) for v in values):
                mean_val = np.mean(values)
                std_val = np.std(values)
                cv = std_val / abs(mean_val) if mean_val != 0 else float('inf')
                stability_scores[param_name] = {
                    'type': 'numeric',
                    'mean': float(mean_val),
                    'std': float(std_val),
                    'cv': float(cv),
                    'values': values
                }
                
                # –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è –ø–æ –Ω–µ—Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
                if cv > self.validation_config['max_parameter_variation_cv']:
                    warnings.append(f'‚ö†Ô∏è –ù–µ—Å—Ç–∞–±–∏–ª—å–Ω—ã–π –ø–∞—Ä–∞–º–µ—Ç—Ä {param_name}: CV={cv:.2f}')
            
            else:
                # –î–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ - —á–∞—Å—Ç–æ—Ç–∞ –≤—Å—Ç—Ä–µ—á–∞–µ–º–æ—Å—Ç–∏
                from collections import Counter
                value_counts = Counter(values)
                most_common_freq = value_counts.most_common(1)[0][1] / len(values)
                
                stability_scores[param_name] = {
                    'type': 'categorical',
                    'value_counts': dict(value_counts),
                    'consistency': most_common_freq,
                    'values': values
                }
                
                if most_common_freq < self.overfitting_config['min_parameter_consistency']:
                    warnings.append(f'‚ö†Ô∏è Inconsistent categorical parameter {param_name}')
        
        # –û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        numeric_cvs = [s['cv'] for s in stability_scores.values() if s['type'] == 'numeric']
        categorical_consistencies = [s['consistency'] for s in stability_scores.values() if s['type'] == 'categorical']
        
        overall_stability = 0.0
        if numeric_cvs:
            avg_cv = float(np.mean(numeric_cvs))
            overall_stability += max(0.0, 1 - avg_cv) * 0.7  # 70% –≤–µ—Å —á–∏—Å–ª–æ–≤—ã–º –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º
        
        if categorical_consistencies:
            avg_consistency = np.mean(categorical_consistencies)
            overall_stability += avg_consistency * 0.3  # 30% –≤–µ—Å –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–º
        
        return {
            'parameter_stability_scores': stability_scores,
            'overall_stability': overall_stability,
            'warnings': warnings
        }
    
    def _analyze_profitability_pattern(self, windows: List[Dict]) -> Dict:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω—ã –ø—Ä–∏–±—ã–ª—å–Ω–æ—Å—Ç–∏ –æ–∫–æ–Ω."""
        profitable_windows = 0
        total_profit = 0.0
        profit_values = []
        
        for window in windows:
            test_metrics = window.get('test_metrics')
            if test_metrics and hasattr(test_metrics, 'total_return_pct'):
                profit_pct = test_metrics.total_return_pct
                profit_values.append(profit_pct)
                total_profit += profit_pct
                if profit_pct > 0:
                    profitable_windows += 1
        
        if not profit_values:
            return {'status': 'no_profit_data'}
        
        profitable_ratio = profitable_windows / len(windows)
        warnings = []
        
        # –°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –ø—Ä–∏–±—ã–ª—å–Ω—ã—Ö –æ–∫–æ–Ω –º–æ–∂–µ—Ç —É–∫–∞–∑—ã–≤–∞—Ç—å –Ω–∞ overfitting
        if profitable_ratio > self.overfitting_config['max_profitable_windows_ratio']:
            warnings.append(f'üö® –ü–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–æ –º–Ω–æ–≥–æ –ø—Ä–∏–±—ã–ª—å–Ω—ã—Ö –æ–∫–æ–Ω: {profitable_ratio:.1%}')
        
        # –ê–Ω–∞–ª–∏–∑ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø—Ä–∏–±—ã–ª–∏
        profit_std = np.std(profit_values)
        profit_mean = np.mean(profit_values)
        
        return {
            'profitable_windows': profitable_windows,
            'total_windows': len(windows),
            'profitable_ratio': profitable_ratio,
            'avg_profit_pct': profit_mean,
            'profit_volatility': profit_std,
            'total_profit_pct': total_profit,
            'warnings': warnings
        }
    
    def _analyze_performance_degradation(self, windows: List[Dict]) -> Dict:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –¥–µ–≥—Ä–∞–¥–∞—Ü–∏—é –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ train‚Üíval‚Üítest."""
        degradations = []
        warnings = []
        
        for window in windows:
            train_score = window.get('train_score', 0)
            val_score = window.get('val_score', 0)
            test_score = window.get('test_score', 0)
            
            if all(score > 0 for score in [train_score, val_score, test_score]):
                train_to_val = (train_score - val_score) / train_score
                val_to_test = (val_score - test_score) / val_score
                train_to_test = (train_score - test_score) / train_score
                
                degradations.append({
                    'window_id': window.get('window_id'),
                    'train_to_val': train_to_val,
                    'val_to_test': val_to_test,
                    'train_to_test': train_to_test
                })
        
        if not degradations:
            return {'status': 'no_data'}
        
        # –°—Ä–µ–¥–Ω–∏–µ –¥–µ–≥—Ä–∞–¥–∞—Ü–∏–∏
        avg_train_to_val = np.mean([d['train_to_val'] for d in degradations])
        avg_val_to_test = np.mean([d['val_to_test'] for d in degradations])
        avg_train_to_test = np.mean([d['train_to_test'] for d in degradations])
        
        # –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è
        if avg_train_to_test > 0.3:
            warnings.append('üî¥ –°–∏–ª—å–Ω–∞—è –¥–µ–≥—Ä–∞–¥–∞—Ü–∏—è –æ—Ç —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏ –∫ —Ç–µ—Å—Ç—É')
        elif avg_train_to_test > 0.15:
            warnings.append('üü° –£–º–µ—Ä–µ–Ω–Ω–∞—è –¥–µ–≥—Ä–∞–¥–∞—Ü–∏—è –æ—Ç —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏ –∫ —Ç–µ—Å—Ç—É')
        
        return {
            'avg_train_to_val_degradation': avg_train_to_val,
            'avg_val_to_test_degradation': avg_val_to_test,
            'avg_train_to_test_degradation': avg_train_to_test,
            'individual_degradations': degradations,
            'warnings': warnings
        }
    
    def _calculate_overfitting_score(self, analysis: Dict) -> float:
        """
        –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –æ–±—â–∏–π score —Ä–∏—Å–∫–∞ overfitting (0-100, –≥–¥–µ 100 = –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∏—Å–∫).
        """
        score = 0.0
        
        # 1. –°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (30% –≤–µ—Å–∞)
        score_stability = analysis.get('score_stability', {})
        test_cv = score_stability.get('test_score_cv', 0)
        score += min(30, test_cv * 50)  # CV > 0.6 –¥–∞—ë—Ç –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–µ 30 –±–∞–ª–ª–æ–≤
        
        # 2. –°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ (25% –≤–µ—Å–∞)
        param_stability = analysis.get('parameter_stability', {})
        overall_stability = param_stability.get('overall_stability', 1.0)
        score += (1 - overall_stability) * 25
        
        # 3. –ü–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–∏–±—ã–ª—å–Ω–æ—Å—Ç—å (25% –≤–µ—Å–∞)
        profitability = analysis.get('profitability', {})
        profitable_ratio = profitability.get('profitable_ratio', 0.5)
        if profitable_ratio > 0.8:
            score += (profitable_ratio - 0.8) * 125  # –ú–∞–∫—Å–∏–º—É–º 25 –±–∞–ª–ª–æ–≤
        
        # 4. –î–µ–≥—Ä–∞–¥–∞—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ (20% –≤–µ—Å–∞)
        degradation = analysis.get('degradation', {})
        avg_degradation = degradation.get('avg_train_to_test_degradation', 0)
        score += min(20, avg_degradation * 50)  # –î–µ–≥—Ä–∞–¥–∞—Ü–∏—è > 0.4 –¥–∞—ë—Ç –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–µ 20 –±–∞–ª–ª–æ–≤
        
        return min(100, score)
    
    def validate_robustness(self, best_params: Dict, strategy_config_path: str, 
                           data: pd.DataFrame, objective_func) -> Dict:
        """
        –¢–µ—Å—Ç —Ä–æ–±–∞—Å—Ç–Ω–æ—Å—Ç–∏: –ø—Ä–æ–≤–µ—Ä—è–µ—Ç —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –ø—Ä–∏ –Ω–µ–±–æ–ª—å—à–∏—Ö –∏–∑–º–µ–Ω–µ–Ω–∏—è—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤.
        
        Args:
            best_params: –õ—É—á—à–∏–µ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
            strategy_config_path: –ü—É—Ç—å –∫ –∫–æ–Ω—Ñ–∏–≥—É —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
            data: –î–∞–Ω–Ω—ã–µ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
            objective_func: –§—É–Ω–∫—Ü–∏—è –æ—Ü–µ–Ω–∫–∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
            
        Returns:
            Dict: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–∞ —Ä–æ–±–∞—Å—Ç–Ω–æ—Å—Ç–∏
        """
        noise_level = self.validation_config['parameter_noise_level']
        n_variations = self.validation_config['robustness_test_variations']
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –≤–∞—Ä–∏–∞—Ü–∏–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        parameter_variations = self._generate_parameter_variations(
            best_params, noise_level, n_variations
        )
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –∫–∞–∂–¥—É—é –≤–∞—Ä–∏–∞—Ü–∏—é
        scores = []
        for variation in parameter_variations:
            try:
                result = objective_func.evaluate_fixed_params(
                    variation, data, strategy_config_path, mode='robustness'
                )
                scores.append(result['score'])
            except Exception as e:
                self.logger.debug(f"–û—à–∏–±–∫–∞ –≤ robustness test: {e}")
                scores.append(0.0)  # –®—Ç—Ä–∞—Ñ–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        original_score = objective_func.evaluate_fixed_params(
            best_params, data, strategy_config_path, mode='robustness'
        )['score']
        
        scores_array = np.array(scores)
        mean_score = np.mean(scores_array)
        std_score = np.std(scores_array)
        
        # –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
        stability_coefficient = 1 - (std_score / abs(mean_score)) if mean_score != 0 else 0
        
        # –ü—Ä–æ—Ü–µ–Ω—Ç –≤–∞—Ä–∏–∞—Ü–∏–π –ª—É—á—à–µ –æ—Ä–∏–≥–∏–Ω–∞–ª–∞
        better_variations = np.sum(scores_array > original_score) / len(scores_array)
        
        return {
            'original_score': original_score,
            'variation_scores': scores,
            'mean_variation_score': mean_score,
            'std_variation_score': std_score,
            'stability_coefficient': stability_coefficient,
            'better_variations_pct': better_variations,
            'robust': stability_coefficient > 0.7 and better_variations < 0.3
        }
    
    def _generate_parameter_variations(self, base_params: Dict, noise_level: float, 
                                     n_variations: int) -> List[Dict]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –≤–∞—Ä–∏–∞—Ü–∏–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —Å –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ–º —à—É–º–∞."""
        variations = []
        
        for _ in range(n_variations):
            variation = {}
            for param_name, base_value in base_params.items():
                if isinstance(base_value, (int, float)):
                    # –î–æ–±–∞–≤–ª—è–µ–º –≥–∞—É—Å—Å–æ–≤—Å–∫–∏–π —à—É–º
                    noise = np.random.normal(0, abs(base_value) * noise_level)
                    new_value = base_value + noise
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–∏–ø –ø–∞—Ä–∞–º–µ—Ç—Ä–∞
                    if isinstance(base_value, int):
                        variation[param_name] = int(round(new_value))
                    else:
                        variation[param_name] = new_value
                else:
                    # –î–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –æ—Å—Ç–∞–≤–ª—è–µ–º –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π
                    variation[param_name] = base_value
            
            variations.append(variation)
        
        return variations